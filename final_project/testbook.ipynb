{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 1: Select what features you'll use.\n",
    "# features_list is a list of strings, each of which is a feature name.\n",
    "# The first feature must be \"poi\".\n",
    "\n",
    "\"\"\"\n",
    "features = ['poi',\n",
    "            'bonus',\n",
    "            'deferral_payments',\n",
    "            'deferred_income',\n",
    "            'director_fees',\n",
    "            'email_address',\n",
    "            'exercised_stock_options',\n",
    "            'expenses',\n",
    "            'from_messages',\n",
    "            'from_poi_to_this_person',\n",
    "            'from_this_person_to_poi',\n",
    "            'loan_advances',\n",
    "            'long_term_incentive',\n",
    "            'other',\n",
    "            'restricted_stock',\n",
    "            'restricted_stock_deferred',\n",
    "            'salary',\n",
    "            'shared_receipt_with_poi',\n",
    "            'to_messages',\n",
    "            'total_payments',\n",
    "            'total_stock_value']\n",
    "\"\"\"\n",
    "\n",
    "features_list = ['poi',\n",
    "            'bonus',\n",
    "            'deferral_payments',\n",
    "            'deferred_income',\n",
    "            'director_fees',\n",
    "            'exercised_stock_options',\n",
    "            'expenses',\n",
    "            'from_messages',\n",
    "            'from_poi_to_this_person',\n",
    "            'from_this_person_to_poi',\n",
    "            'loan_advances',\n",
    "            'long_term_incentive',\n",
    "            'restricted_stock',\n",
    "            'restricted_stock_deferred',\n",
    "            'salary',\n",
    "            'shared_receipt_with_poi',\n",
    "            'to_messages',\n",
    "            'total_payments',\n",
    "            'total_stock_value',\n",
    "                 'relative_messages_to_poi',\n",
    "                 'relative_messages_from_poi']\n",
    "\n",
    "# Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# Task 2: Remove outliers / data preparation\n",
    "outliers = ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK']  # See notebook data exploration\n",
    "\n",
    "for outlier in outliers:\n",
    "    del data_dict[outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for employee in data_dict:\n",
    "    to_messages = data_dict[employee]['to_messages']\n",
    "    from_messages = data_dict[employee]['from_messages']\n",
    "    from_poi_to_this_person = data_dict[employee]['from_poi_to_this_person']\n",
    "    from_this_person_to_poi = data_dict[employee]['from_this_person_to_poi']\n",
    "    \n",
    "    if to_messages == 'NaN' or from_messages == 'NaN' or from_poi_to_this_person == 'NaN' or from_this_person_to_poi == 'NaN':\n",
    "        data_dict[employee]['relative_messages_from_poi'] = 'NaN'\n",
    "        data_dict[employee]['relative_messages_to_poi'] = 'NaN'\n",
    "    else:\n",
    "        to_messages = float(to_messages)\n",
    "        from_messages = float(from_messages)\n",
    "        from_poi_to_this_person = float(from_poi_to_this_person)\n",
    "        from_this_person_to_poi = float(from_this_person_to_poi)\n",
    "        data_dict[employee]['relative_messages_from_poi'] = from_poi_to_this_person/to_messages\n",
    "        data_dict[employee]['relative_messages_to_poi'] = from_this_person_to_poi/from_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remaining issue: because some `to_message` entries are \"NaN\", the result of the division above will be the genuine NaN. These entries will not be converted to zero when handled by featureFormat().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NaN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(data_dict, orient='index').loc['BADUM JAMES P','relative_messages_to_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 3: Create new feature(s)\n",
    "df_data = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "numeric_columns = ['salary',\n",
    "                   'to_messages',\n",
    "                   'deferral_payments',\n",
    "                   'total_payments',\n",
    "                   'exercised_stock_options',\n",
    "                   'bonus',\n",
    "                   'restricted_stock',\n",
    "                   'shared_receipt_with_poi',\n",
    "                   'restricted_stock_deferred',\n",
    "                   'total_stock_value',\n",
    "                   'expenses',\n",
    "                   'loan_advances',\n",
    "                   'from_messages',\n",
    "                   'other',\n",
    "                   'from_this_person_to_poi',\n",
    "                   'director_fees',\n",
    "                   'deferred_income',\n",
    "                   'long_term_incentive',\n",
    "                   'from_poi_to_this_person']\n",
    "\n",
    "df_data[numeric_columns] = df_data[numeric_columns].astype(float)\n",
    "df_data['relative_messages_to_poi'] = df_data.from_this_person_to_poi/df_data.from_messages\n",
    "df_data['relative_messages_from_poi'] = df_data.from_poi_to_this_person/df_data.to_messages\n",
    "df_data = df_data[features_list]\n",
    "df_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict = df_data.to_dict(orient='index')\n",
    "\n",
    "# Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "best_features = SelectKBest(f_classif, k=5).fit_transform(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(best_features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.860465116279\n",
      "Precision: 0.5\n",
      "Recall: 0.5\n",
      "Confusion matrix:\n",
      "array([[34,  3],\n",
      "       [ 3,  3]])\n",
      "Relative feature importances:\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "run_classifier(features_train, labels_train, features_test, labels_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_classifier(features_train, labels_train, features_test, labels_test, clf):\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    print 'Accuracy:', clf.score(features_test, labels_test)\n",
    "    print 'Precision:', precision_score(labels_test, pred)\n",
    "    print 'Recall:', recall_score(labels_test, pred)\n",
    "    \n",
    "    print 'Confusion matrix:'\n",
    "    pprint(confusion_matrix(labels_test, pred))\n",
    "    \n",
    "    try:\n",
    "        print 'Relative feature importances:'\n",
    "        print clf.feature_importances_\n",
    "    except:\n",
    "        print '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.860465116279\n",
      "Precision: 0.5\n",
      "Recall: 0.5\n",
      "Confusion matrix:\n",
      "array([[34,  3],\n",
      "       [ 3,  3]])\n",
      "Relative feature importances:\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "run_classifier(features_train, labels_train, features_test, labels_test, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "params = {'kernel':['linear', 'rbf', 'sigmoid'],\n",
    "          'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "          'gamma': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "clf = SVC()\n",
    "clf = GridSearchCV(clf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "parameters = {'min_samples_split': [2, 5, 10, 20, 50, 100, 1000]}\n",
    "clf = GridSearchCV(clf, parameters)\n",
    "clf = clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print recall_score(labels_test, pred)\n",
    "print precision_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.837209302326\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Confusion matrix:\n",
      "array([[36,  1],\n",
      "       [ 6,  0]])\n",
      "Relative feature importances:\n",
      "[ 0.19609696  0.04574428  0.          0.01246332  0.0996377   0.00315573\n",
      "  0.14885773  0.23340473  0.12481834  0.1358212 ]\n"
     ]
    }
   ],
   "source": [
    "run_classifier(features_train, labels_train, features_test, labels_test, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.837209302326\n",
      "Precision: 0.333333333333\n",
      "Recall: 0.166666666667\n",
      "Confusion matrix:\n",
      "array([[35,  2],\n",
      "       [ 5,  1]])\n",
      "Relative feature importances:\n",
      "[ 0.12  0.22  0.    0.06  0.06  0.14  0.1   0.08  0.04  0.18]\n"
     ]
    }
   ],
   "source": [
    "run_classifier(features_train, labels_train, features_test, labels_test, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2, 5, 10, 20, 50, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'min_samples_split': [2, 5, 10, 20, 50, 100, 1000]}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters)\n",
    "clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 100}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87878787878787878"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
